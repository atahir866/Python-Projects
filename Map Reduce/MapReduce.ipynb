{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some necessary code\n",
    "from collections import defaultdict, Counter\n",
    "import re, datetime\n",
    "from functools import partial\n",
    "import os\n",
    "from IPython.display import display\n",
    "import sys\n",
    "\n",
    "def tokenize(message):\n",
    "    message = message.lower()                       # convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9']+\", message)   # extract the words\n",
    "    return (all_words)                           # remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1\n",
    "###  Top n words from list of document files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a generic map reduce function for question 2,3,4\n",
    "\n",
    "def map_reduce(inputs, mapper, reducer,n=None,a=None):\n",
    "    \n",
    "    collector = defaultdict(list)\n",
    "    \n",
    "    # writing a for loop over the inputs that calls mapper\n",
    "    for input in inputs:\n",
    "        for key, value in mapper(input):\n",
    "            collector[key].append(value)\n",
    "    \n",
    "    # return statement that calls the reducer       \n",
    "    \n",
    "    return [output\n",
    "           for key, value in collector.items()\n",
    "           for output in reducer(key,value,n,a)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining a mapper which will read files and yield word with a count 1 for all files\n",
    "\n",
    "def file_mapper(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "            for line in f: \n",
    "                for word in tokenize(line):\n",
    "                    yield ('Top_n_words',(word,1))\n",
    "\n",
    "# defining a reducer which will sum the counts for each word and return n words with highest counts\n",
    "\n",
    "def sum_max_reducer(files,words_and_counts,n,a):\n",
    "    word_counts=Counter()\n",
    "    for word,count in words_and_counts:\n",
    "        word_counts[word]+=count\n",
    "        \n",
    "# find n most common words and return that (key,value) pair    \n",
    "    \n",
    "    yield (files,word_counts.most_common(n))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Top_n_words',\n",
       "  [('and', 7478),\n",
       "   ('the', 6041),\n",
       "   ('of', 3330),\n",
       "   ('he', 1769),\n",
       "   ('to', 1634),\n",
       "   ('in', 1419)])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"dataset1/genesis.txt\",\n",
    "            \"dataset1/Luke.txt\",\n",
    "            \"dataset1/Kings.txt\"]\n",
    "word_counts = map_reduce(filenames, file_mapper, sum_max_reducer,6)\n",
    "word_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>7478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  names  counts\n",
       "0   and    7478\n",
       "1   the    6041\n",
       "2    of    3330\n",
       "3    he    1769\n",
       "4    to    1634\n",
       "5    in    1419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting output list of tuples into pandas dataframe to make it visually better.\n",
    "import pandas as pd\n",
    "x=word_counts[0][1]\n",
    "a=[]\n",
    "b=[]\n",
    "for i in x:\n",
    "    a.append(i[0])\n",
    "    b.append(i[1])\n",
    "\n",
    "display(pd.DataFrame({'names':a,\n",
    "             'counts':b},columns=['names','counts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2\n",
    "### 'n' most common names that start with a given letter from a list of files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining a mapper which will read files and yield word with a count 1 for all files\n",
    "\n",
    "def files_mapper(file):\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f: \n",
    "            for word in tokenizes(line):\n",
    "                yield ('Top_N_words',(word,1))\n",
    "                \n",
    "# redefining tokenize function to extract only name from files\n",
    "\n",
    "def tokenizes(message):\n",
    "    x,y,z=message.split(',')\n",
    "    x = x.lower()                       # convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9']+\", x)   # extract the words\n",
    "    return (all_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining a reducer which will sum the counts for each word and return n words with highest counts\n",
    "# if starting letter of name is equal to our input character\n",
    "\n",
    "def reducer_most_common_letter_start(files,words_and_counts,n,a):\n",
    "    word_counts=Counter()\n",
    "    for word,count in words_and_counts:\n",
    "        if word[0]==a:\n",
    "            word_counts[word]+=count\n",
    "            \n",
    "    if len(word_counts)>n:\n",
    "        yield (files,word_counts.most_common(n))\n",
    "    else:\n",
    "        yield (files,word_counts.most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Top_N_words', [('quincy', 238), ('quinn', 160), ('queen', 142), ('quentin', 141), ('queenie', 132), ('quinton', 118), ('quintin', 106), ('quincey', 105), ('quinten', 98), ('quin', 98), ('quenton', 93), ('quince', 76)])]\n"
     ]
    }
   ],
   "source": [
    "arr_txt = [x for x in os.listdir() if x.endswith(\".txt\")]\n",
    "word_counts = map_reduce(arr_txt, files_mapper, reducer_most_common_letter_start,12,'q')\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quincy</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quinn</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>queen</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queenie</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quinton</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quintin</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quincey</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quinten</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quin</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>quenton</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quince</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      names  counts\n",
       "0    quincy     238\n",
       "1     quinn     160\n",
       "2     queen     142\n",
       "3   quentin     141\n",
       "4   queenie     132\n",
       "5   quinton     118\n",
       "6   quintin     106\n",
       "7   quincey     105\n",
       "8   quinten      98\n",
       "9      quin      98\n",
       "10  quenton      93\n",
       "11   quince      76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting output list of tuples into pandas dataframe to make it visually better.\n",
    "import pandas as pd\n",
    "x=word_counts[0][1]\n",
    "a=[]\n",
    "b=[]\n",
    "for i in x:\n",
    "    a.append(i[0])\n",
    "    b.append(i[1])\n",
    "\n",
    "display(pd.DataFrame({'names':a,\n",
    "             'counts':b},columns=['names','counts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 3\n",
    "### top 'n' names from a list of files that contain a given string anywhere within a name in a list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining a mapper which will read files and yield word with a count 1 for all files\n",
    "\n",
    "def files_mapper(file):\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f: \n",
    "            for word in tokenizes(line):\n",
    "                yield ('Top_N_words',(word,1))\n",
    "\n",
    "# defining a reducer which will sum the counts for each word and return n words with highest counts\n",
    "# if our input string is present anywhere in the name\n",
    "\n",
    "def letter_most_occuring(files,words_and_counts,n,a):\n",
    "    word_counts=Counter()\n",
    "    for word,count in words_and_counts:\n",
    "        if a in word:\n",
    "            word_counts[word]+=count\n",
    "    if len(word_counts)>n:\n",
    "        yield (files,word_counts.most_common(n))\n",
    "    else:\n",
    "        yield (files,word_counts.most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Top_N_words', [('elizabeth', 273), ('kenneth', 237), ('ethel', 217), ('bethel', 197), ('seth', 177), ('beth', 166), ('ethan', 148), ('elisabeth', 141), ('elizebeth', 137), ('letha', 135)])]\n"
     ]
    }
   ],
   "source": [
    "word_counts = map_reduce(arr_txt, files_mapper, letter_most_occuring,10,'eth')\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elizabeth</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kenneth</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ethel</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bethel</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seth</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beth</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ethan</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>elisabeth</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elizebeth</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>letha</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       names  counts\n",
       "0  elizabeth     273\n",
       "1    kenneth     237\n",
       "2      ethel     217\n",
       "3     bethel     197\n",
       "4       seth     177\n",
       "5       beth     166\n",
       "6      ethan     148\n",
       "7  elisabeth     141\n",
       "8  elizebeth     137\n",
       "9      letha     135"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting output list of tuples into pandas dataframe to make it visually better.\n",
    "import pandas as pd\n",
    "x=word_counts[0][1]\n",
    "a=[]\n",
    "b=[]\n",
    "for i in x:\n",
    "    a.append(i[0])\n",
    "    b.append(i[1])\n",
    "pd.DataFrame({'names':a,\n",
    "             'counts':b},columns=['names','counts'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
